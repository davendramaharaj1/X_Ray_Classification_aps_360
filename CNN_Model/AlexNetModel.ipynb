{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNetModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExbljdUu0hL6"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up8j3Sdx1igI",
        "outputId": "77d8e0a9-02c3-40f7-c626-c199cffa9abc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEhuq3IW2xuq"
      },
      "source": [
        "def load_data(batch_size=64):\n",
        "  # Compose allows us to have multiple transformations to occur\n",
        "  # and resize all images to 224x224\n",
        "  transform_it = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
        "\n",
        "  # Save the paths of each of the different types of data that are located in my drive \n",
        "  train_path = '/content/gdrive/MyDrive/Primary Models/sample_large/train'\n",
        "  val_path = '/content/gdrive/MyDrive/Primary Models/sample_large/val'\n",
        "  test_path = '/content/gdrive/MyDrive/Primary Models/sample_large/test'\n",
        "\n",
        "  # Load all of the data from my google drive\n",
        "  train_data = torchvision.datasets.ImageFolder(train_path, transform=transform_it)\n",
        "  val_data = torchvision.datasets.ImageFolder(val_path, transform=transform_it)\n",
        "  test_data = torchvision.datasets.ImageFolder(test_path, transform=transform_it)\n",
        "\n",
        "  return train_data, val_data, test_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9zTOTWr15CI"
      },
      "source": [
        "import torchvision.models\n",
        "alexnet = torchvision.models.alexnet(pretrained=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjqultkH3B81",
        "outputId": "396f6d24-9e95-4f71-f613-7629a8af3139"
      },
      "source": [
        "train_data, val_data, test_data = load_data()\n",
        "# TRAINING EXAMPLES\n",
        "print(\"Training Examples:\", len(train_data))\n",
        "\n",
        "#VALIDATION EXMAPLES \n",
        "print(\"Validation Examples:\", len(val_data))\n",
        "\n",
        "#TEST EXAMPLES \n",
        "print(\"Test Examples:\", len(test_data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Examples: 669\n",
            "Validation Examples: 143\n",
            "Test Examples: 138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQDKr_gO3b7S"
      },
      "source": [
        "# Load all of the data such as training, validation and test\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, num_workers=1, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=1, num_workers=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=1, shuffle=True)\n",
        "\n",
        "# Create a function to save all the features into the folders \n",
        "def load_features(loader, new_main_dir, folder):\n",
        "  classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
        "\n",
        "  n = 0\n",
        "  for img, label in loader:\n",
        "    # Get the features of each image and transform to a tensor \n",
        "    feature = alexnet.features(img)\n",
        "    feature_tensor = torch.from_numpy(feature.detach().numpy())\n",
        "\n",
        "    # Save those features into folder \n",
        "    feature_dir = new_main_dir + '/' + str(folder) + '/' + str(classes[label])\n",
        "    if not os.path.isdir(feature_dir):\n",
        "      os.mkdir(feature_dir)\n",
        "    torch.save(feature_tensor.squeeze(0), feature_dir + '/' + str(n) + '.tensor')\n",
        "\n",
        "    n+=1\n",
        "\n",
        "  print(\"Features done for \", folder)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH3gYo8T4Cwf"
      },
      "source": [
        "load_features(train_loader, /content/gdrive/MyDrive/Primary Models/Transfer Learning/AlexNet, 'Train')\n",
        "load_features(val_loader,/content/gdrive/MyDrive/Primary Models/Transfer Learning/AlexNet,'Validation')\n",
        "load_features(test_loader,/content/gdrive/MyDrive/Primary Models/Transfer Learning/AlexNet,'Test')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}