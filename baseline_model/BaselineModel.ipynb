{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4cIPNBc1zhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefdc861-fcb1-40b6-c112-1da36fcd0a6e"
      },
      "source": [
        "import numpy as np\r\n",
        "import time\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import torchvision\r\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torchvision.models\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.externals import joblib\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu6cwQ4KkvEx",
        "outputId": "7dbe5cf3-6475-408a-f24a-aa084ed93e88"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgGbz85umHM7"
      },
      "source": [
        "def loadData():\r\n",
        "  np.random.seed(1000) \r\n",
        "  #Ensuring data is a 224x224 image, used the centercrop function to crop at center\r\n",
        "  transform = transforms.Compose([transforms.Resize((224,224)), \r\n",
        "                                transforms.ToTensor()])\r\n",
        "\r\n",
        "  \r\n",
        "  numWorkers = 1\r\n",
        "  batchSize = 1\r\n",
        "\r\n",
        "  classes = ['COVID-19', 'Normal', 'Pneumonial-Bacterial', 'Pneumonial-Viral']\r\n",
        "  #datasetPath = '/content/gdrive/MyDrive/APS360/ProgressReport/APS360SampleData'\r\n",
        "\r\n",
        "  datasetPath = '/content/gdrive/MyDrive/APS360/ProgressReport/SampleDataLarge'\r\n",
        "\r\n",
        "\r\n",
        "  sampleSet = torchvision.datasets.ImageFolder(datasetPath, transform=transform)\r\n",
        "  print(len(sampleSet))\r\n",
        "  #All the data loaded is valid so we can use any index\r\n",
        "  train = int((len(sampleSet) * 0.8))\r\n",
        "  val = int((len(sampleSet) * 0.1))\r\n",
        "  test = int((len(sampleSet) * 0.1))\r\n",
        "\r\n",
        "  # Used the random_split data function to split the dataset into a 70, 20, 10 proportion \r\n",
        "  trainData, valData, testData = torch.utils.data.random_split(sampleSet,\r\n",
        "                  [train,val,test],generator=torch.Generator().manual_seed(100))\r\n",
        "  \r\n",
        "  print(trainData, valData, testData)  \r\n",
        "\r\n",
        "  #Load all the data\r\n",
        "  trainLoader = torch.utils.data.DataLoader(trainData, batch_size=batchSize, \r\n",
        "                                            num_workers= numWorkers,\r\n",
        "                                            shuffle=True)\r\n",
        "  valLoader = torch.utils.data.DataLoader(valData, batch_size=batchSize, \r\n",
        "                                          num_workers= numWorkers,\r\n",
        "                                                  shuffle=True)\r\n",
        "  testLoader = torch.utils.data.DataLoader(testData, batch_size=batchSize, \r\n",
        "                                           num_workers= numWorkers,\r\n",
        "                                                  shuffle=True)\r\n",
        "  return trainLoader, valLoader, testLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8KJu6JHmrCo",
        "outputId": "336cc2f6-a9be-409c-b6a9-75e28ae738ce"
      },
      "source": [
        "test = loadData()\r\n",
        "trainLoader = test[0]\r\n",
        "valLoader = test[1]\r\n",
        "testLoader = test[2]\r\n",
        "print(len(trainLoader),len(valLoader),len(testLoader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "950\n",
            "<torch.utils.data.dataset.Subset object at 0x7ff15ab7e310> <torch.utils.data.dataset.Subset object at 0x7ff15ab7ed10> <torch.utils.data.dataset.Subset object at 0x7ff15ab7ef90>\n",
            "760 95 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKlC52onnH0J"
      },
      "source": [
        "# classes = ['COVID-19', 'Normal', 'Pneumonial-Bacterial', 'Pneumonial-Viral']\r\n",
        "# dataiter = iter(trainLoader)\r\n",
        "# images, labels = dataiter.next()\r\n",
        "# image = np.transpose(images[0], (1, 2, 0))\r\n",
        "# label = classes[labels[0]]\r\n",
        "# for images, labels in trainLoader:\r\n",
        "#   print(classes[labels[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDq66NPmu9QV"
      },
      "source": [
        "#links\r\n",
        "#https://towardsdatascience.com/dealing-with-multiclass-data-78a1a27c5dcc\r\n",
        "#https://www.codementor.io/@agarrahul01/multiclass-classification-using-random-forest-on-scikit-learn-library-hkk4lwawu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqcEK0KIvhqa",
        "outputId": "bb36a3eb-6431-494e-abe3-d5765546ceb6"
      },
      "source": [
        "train_x = []\r\n",
        "train_y = []\r\n",
        "\r\n",
        "for x, y in trainLoader:\r\n",
        "  train_x.append(x)\r\n",
        "  train_y.append(y)\r\n",
        "\r\n",
        "train_x = torch.stack(train_x)\r\n",
        "train_y = torch.stack(train_y)\r\n",
        "train_x = train_x.reshape(760, 224*224*3)\r\n",
        "print(train_x.shape)\r\n",
        "print(train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([760, 150528])\n",
            "torch.Size([760, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJKjltiUztfK",
        "outputId": "0d56d12c-a3d8-4a4b-bebe-249443fabce5"
      },
      "source": [
        "test_x = []\r\n",
        "test_y = []\r\n",
        "for x, y in testLoader:\r\n",
        "  test_x.append(x)\r\n",
        "  test_y.append(y)\r\n",
        "\r\n",
        "test_x = torch.stack(test_x)\r\n",
        "test_x = test_x.reshape(95, 224*224*3)\r\n",
        "test_y = torch.stack(test_y)\r\n",
        "print(test_x.shape)\r\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([95, 150528])\n",
            "torch.Size([95, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDdciTglxv5h",
        "outputId": "5f663195-6373-427c-e9b7-4ec28fbe0e0d"
      },
      "source": [
        "# Create a Gaussian Classfier\r\n",
        "model = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 20)\r\n",
        "model.fit(train_x,train_y)\r\n",
        "predict2 = model.predict(train_x)\r\n",
        "predict = model.predict(test_x)\r\n",
        "value = accuracy_score(test_y,predict)\r\n",
        "value2 = accuracy_score(train_y,predict2)\r\n",
        "print(value)\r\n",
        "print(value2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7157894736842105\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}