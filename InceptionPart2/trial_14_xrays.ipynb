{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quiet-blink",
   "metadata": {
    "id": "choice-exhibit"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session\n",
    "# import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-platinum",
   "metadata": {
    "id": "english-mouth"
   },
   "source": [
    "## Create bucket & Validation Region for S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "portable-cream",
   "metadata": {
    "id": "immediate-worry",
    "outputId": "cf6bb887-ee32-4ef7-80c5-5b4dfc80053a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'aps360' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-olympus",
   "metadata": {
    "id": "serious-photographer"
   },
   "source": [
    "## Create Paths to S3 Buckets for storage of model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "classified-globe",
   "metadata": {
    "id": "instrumental-welding",
    "outputId": "dcd771c8-ee7e-474f-c23e-57f832ab72c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory <dataset_dir>:  s3://aps360/xrayclassification/Xray_Dataset\n",
      "Model Output directory <output_dir>:  s3://aps360/xrayclassification/trial_14\n"
     ]
    }
   ],
   "source": [
    "# Prefix for files in bucket\n",
    "prefix = 'xrayclassification'\n",
    "\n",
    "# Dataset directory\n",
    "dataset = 'Xray_Dataset'\n",
    "\n",
    "# Model output folder name\n",
    "output_dir_name = 'trial_14'\n",
    "\n",
    "# S3 Path bucket to get the data for training (Train, Test, Validation)\n",
    "dataset_dir = 's3://{}/{}/{}'.format(bucket_name, prefix, dataset)\n",
    "\n",
    "# output path for SageMaker to dump all model artifacts and graphs etc\n",
    "output_dir = 's3://{}/{}/{}'.format(bucket_name, prefix, output_dir_name)\n",
    "\n",
    "# # checkpoints for spot training\n",
    "# checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "# checkpoint_s3_path = 's3://{}/{}/{}/checkpoint-{}'.format(bucket_name, prefix, output_dir_name, checkpoint_suffix)\n",
    "\n",
    "# sanity check for output path for model data\n",
    "print('Dataset directory <dataset_dir>: ', dataset_dir)\n",
    "print('Model Output directory <output_dir>: ', output_dir)\n",
    "# print('Checkpointing Path: <checkpoint_s3_path>: {}'.format(checkpoint_s3_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-default",
   "metadata": {
    "id": "swedish-dynamics"
   },
   "source": [
    "## Manage Spot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parental-player",
   "metadata": {
    "id": "prime-miami"
   },
   "outputs": [],
   "source": [
    "# use_spot_instances = True\n",
    "# max_run=24*60*60\n",
    "# max_wait = 24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sealed-cartoon",
   "metadata": {
    "id": "infinite-hungary"
   },
   "outputs": [],
   "source": [
    "# initialize hyperparamters\n",
    "hyperparameters = {\n",
    "    'epochs': 12,\n",
    "    'batch-size': 64,\n",
    "    'learning-rate': 0.0005 \n",
    "}\n",
    "\n",
    "# Training instance\n",
    "training_instance = 'ml.g4dn.2xlarge'\n",
    "\n",
    "# Create the current role to use sagemaker \n",
    "role = sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "israeli-moldova",
   "metadata": {
    "id": "polish-laptop",
    "outputId": "73a3a064-194b-4b80-e6ef-a1b1f1dfb81f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create a Pytorch estimator to run the training script on AWS Sagemaker\n",
    "estimator = PyTorch(\n",
    "                entry_point='trial14xray.py',\n",
    "                role=role,\n",
    "                framework_version='1.8.0',\n",
    "                py_version='py3',\n",
    "                output_path=output_dir,\n",
    "                train_instance_count=1,\n",
    "                script_mode=True,\n",
    "                train_instance_type=training_instance,\n",
    "                hyperparameters= hyperparameters,\n",
    "                base_job_name='trial-14-pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-copying",
   "metadata": {
    "id": "caroline-anchor",
    "outputId": "ca3c9149-608d-4f34-80d6-32ea44536eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-03 19:46:17 Starting - Starting the training job...\n",
      "2021-04-03 19:46:39 Starting - Launching requested ML instancesProfilerReport-1617479176: InProgress\n",
      "......\n",
      "2021-04-03 19:47:39 Starting - Preparing the instances for training......\n",
      "2021-04-03 19:48:40 Downloading - Downloading input data...\n",
      "2021-04-03 19:49:12 Training - Downloading the training image................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-04-03 19:51:49,941 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-04-03 19:51:49,962 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-04-03 19:51:52,990 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-04-03 19:51:53,401 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"learning-rate\": 0.0005,\n",
      "        \"epochs\": 12\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"trial-14-pytorch-2021-04-03-19-46-16-517\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://aps360/trial-14-pytorch-2021-04-03-19-46-16-517/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"trial14xray\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"trial14xray.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":12,\"learning-rate\":0.0005}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=trial14xray.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=trial14xray\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://aps360/trial-14-pytorch-2021-04-03-19-46-16-517/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":12,\"learning-rate\":0.0005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"trial-14-pytorch-2021-04-03-19-46-16-517\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://aps360/trial-14-pytorch-2021-04-03-19-46-16-517/source/sourcedir.tar.gz\",\"module_name\":\"trial14xray\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"trial14xray.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"12\",\"--learning-rate\",\"0.0005\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.0005\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=12\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 trial14xray.py --batch-size 64 --epochs 12 --learning-rate 0.0005\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCUDA is available!  Training on GPU ...\u001b[0m\n",
      "\u001b[34mTraining data: 3080\u001b[0m\n",
      "\u001b[34mTraining Augmented data: 4616\u001b[0m\n",
      "\u001b[34mValidation data: 1020\u001b[0m\n",
      "\u001b[34mTesting data: 1024\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:01.564 algo-1:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:01.650 algo-1:25 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:01.651 algo-1:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:01.651 algo-1:25 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:01.651 algo-1:25 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:01.652 algo-1:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\n",
      "2021-04-03 19:52:01 Training - Training image download completed. Training in progress.\u001b[34m[2021-04-03 19:52:06.050 algo-1:25 INFO hook.py:584] name:AuxLogits.fc.weight count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:AuxLogits.fc.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.0.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.0.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.1.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.2.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.4.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:584] name:fc.4.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.051 algo-1:25 INFO hook.py:586] Total Trainable Params: 2630152\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.052 algo-1:25 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-04-03 19:52:06.054 algo-1:25 INFO hook.py:476] Hook is writing from the hook with pid: 25\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 0: Train acc: 0.5593587521663779 | Validation acc: 0.4823529411764706\u001b[0m\n",
      "\u001b[34mEpoch 0: Train acc: 0.5593587521663779 | Validation acc: 0.4823529411764706\u001b[0m\n",
      "\u001b[34mEpoch 1: Train acc: 0.6637781629116117 | Validation acc: 0.5774509803921568\u001b[0m\n",
      "\u001b[34mEpoch 1: Train acc: 0.6637781629116117 | Validation acc: 0.5774509803921568\u001b[0m\n",
      "\u001b[34mEpoch 2: Train acc: 0.6817590987868284 | Validation acc: 0.6176470588235294\u001b[0m\n",
      "\u001b[34mEpoch 2: Train acc: 0.6817590987868284 | Validation acc: 0.6176470588235294\u001b[0m\n",
      "\u001b[34mEpoch 3: Train acc: 0.7110051993067591 | Validation acc: 0.6215686274509804\u001b[0m\n",
      "\u001b[34mEpoch 3: Train acc: 0.7110051993067591 | Validation acc: 0.6215686274509804\u001b[0m\n",
      "\u001b[34mEpoch 4: Train acc: 0.7205372616984402 | Validation acc: 0.6166666666666667\u001b[0m\n",
      "\u001b[34mEpoch 4: Train acc: 0.7205372616984402 | Validation acc: 0.6166666666666667\u001b[0m\n",
      "\u001b[34mEpoch 5: Train acc: 0.7346187175043327 | Validation acc: 0.6549019607843137\u001b[0m\n",
      "\u001b[34mEpoch 5: Train acc: 0.7346187175043327 | Validation acc: 0.6549019607843137\u001b[0m\n",
      "\u001b[34mEpoch 6: Train acc: 0.7419844020797227 | Validation acc: 0.638235294117647\u001b[0m\n",
      "\u001b[34mEpoch 6: Train acc: 0.7419844020797227 | Validation acc: 0.638235294117647\u001b[0m\n",
      "\u001b[34mEpoch 8: Train acc: 0.7478336221837089 | Validation acc: 0.6441176470588236\u001b[0m\n",
      "\u001b[34mEpoch 8: Train acc: 0.7478336221837089 | Validation acc: 0.6441176470588236\u001b[0m\n",
      "\u001b[34mEpoch 9: Train acc: 0.7545493934142115 | Validation acc: 0.6607843137254902\u001b[0m\n",
      "\u001b[34mEpoch 9: Train acc: 0.7545493934142115 | Validation acc: 0.6607843137254902\u001b[0m\n",
      "\u001b[34mEpoch 10: Train acc: 0.7521663778162911 | Validation acc: 0.6803921568627451\u001b[0m\n",
      "\u001b[34mEpoch 10: Train acc: 0.7521663778162911 | Validation acc: 0.6803921568627451\u001b[0m\n",
      "\u001b[34mEpoch 11: Train acc: 0.7675476603119584 | Validation acc: 0.6774509803921569\u001b[0m\n",
      "\u001b[34mEpoch 11: Train acc: 0.7675476603119584 | Validation acc: 0.6774509803921569\u001b[0m\n",
      "\u001b[34mTraining Finished! Plotting Graphs...\u001b[0m\n",
      "\u001b[34mTraining Finished! Plotting Graphs...\u001b[0m\n",
      "\u001b[34mTotal time elapsed: 47259.44 seconds\u001b[0m\n",
      "\u001b[34mTotal time elapsed: 47259.44 seconds\u001b[0m\n",
      "\u001b[34mFinal Training Accuracy: 0.8299393414211439\u001b[0m\n",
      "\u001b[34mFinal Training Accuracy: 0.8299393414211439\u001b[0m\n",
      "\u001b[34mFinal Validation Accuracy: 0.711764705882353\u001b[0m\n",
      "\u001b[34mFinal Validation Accuracy: 0.711764705882353\u001b[0m\n",
      "\u001b[34mGraphs plotted...train() exited...\u001b[0m\n",
      "\u001b[34mGraphs plotted...train() exited...\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/104M [00:00<?, ?B/s]#015  4%|▍         | 3.91M/104M [00:00<00:02, 41.0MB/s]#015  7%|▋         | 7.67M/104M [00:00<00:02, 40.1MB/s]#015 11%|█▏        | 11.7M/104M [00:00<00:02, 40.6MB/s]#015 14%|█▎        | 14.3M/104M [00:00<00:02, 34.9MB/s]#015 18%|█▊        | 18.9M/104M [00:00<00:02, 37.8MB/s]#015 21%|██        | 22.0M/104M [00:00<00:02, 35.7MB/s]#015 24%|██▍       | 25.1M/104M [00:00<00:02, 32.0MB/s]#015 28%|██▊       | 29.6M/104M [00:00<00:02, 35.3MB/s]#015 32%|███▏      | 33.4M/104M [00:00<00:02, 36.4MB/s]#015 36%|███▌      | 37.4M/104M [00:01<00:01, 38.0MB/s]#015 41%|████      | 42.8M/104M [00:01<00:01, 42.1MB/s]#015 46%|████▌     | 47.6M/104M [00:01<00:01, 44.1MB/s]#015 50%|█████     | 52.0M/104M [00:01<00:01, 39.4MB/s]#015 54%|█████▍    | 56.0M/104M [00:01<00:01, 40.1MB/s]#015 58%|█████▊    | 60.0M/104M [00:01<00:01, 38.7MB/s]#015 63%|██████▎   | 65.1M/104M [00:01<00:00, 42.2MB/s]#015 68%|██████▊   | 70.4M/104M [00:01<00:00, 45.3MB/s]#015 72%|███████▏  | 75.1M/104M [00:01<00:00, 46.4MB/s]#015 77%|███████▋  | 80.2M/104M [00:02<00:00, 48.2MB/s]#015 83%|████████▎ | 86.0M/104M [00:02<00:00, 51.4MB/s]#015 88%|████████▊ | 91.1M/104M [00:02<00:00, 49.1MB/s]#015 92%|█████████▏| 95.9M/104M [00:02<00:00, 47.0MB/s]#015 97%|█████████▋| 100M/104M [00:02<00:00, 44.2MB/s] #015100%|██████████| 104M/104M [00:02<00:00, 43.0MB/s]\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\u001b[0m\n",
      "\u001b[34mTypeError: not all arguments converted during string formatting\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"trial14xray.py\", line 388, in <module>\n",
      "    train(inceptionv3, args)\n",
      "  File \"trial14xray.py\", line 185, in train\n",
      "    train_loader, val_loader, test_loader = get_data_loader(args.data_dir, args.batch_size)\n",
      "  File \"trial14xray.py\", line 90, in get_data_loader\n",
      "    logger.info('Training data:', len(train_data))\u001b[0m\n",
      "\u001b[34mMessage: 'Training data:'\u001b[0m\n",
      "\u001b[34mArguments: (3080,)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\u001b[0m\n",
      "\u001b[34m2021-04-04 08:59:42,559 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\u001b[0m\n",
      "\u001b[34mTypeError: not all arguments converted during string formatting\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"trial14xray.py\", line 388, in <module>\n",
      "    train(inceptionv3, args)\n",
      "  File \"trial14xray.py\", line 185, in train\n",
      "    train_loader, val_loader, test_loader = get_data_loader(args.data_dir, args.batch_size)\n",
      "  File \"trial14xray.py\", line 92, in get_data_loader\n",
      "    logger.info('Training Augmented data:', len(train_data_new))\u001b[0m\n",
      "\u001b[34mMessage: 'Training Augmented data:'\u001b[0m\n",
      "\u001b[34mArguments: (4616,)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\u001b[0m\n",
      "\u001b[34mTypeError: not all arguments converted during string formatting\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"trial14xray.py\", line 388, in <module>\n",
      "    train(inceptionv3, args)\n",
      "  File \"trial14xray.py\", line 185, in train\n",
      "    train_loader, val_loader, test_loader = get_data_loader(args.data_dir, args.batch_size)\n",
      "  File \"trial14xray.py\", line 94, in get_data_loader\n",
      "    logger.info('Validation data:',len(val_data))\u001b[0m\n",
      "\u001b[34mMessage: 'Validation data:'\u001b[0m\n",
      "\u001b[34mArguments: (1020,)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 840, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 577, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/conda/lib/python3.6/logging/__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\u001b[0m\n",
      "\u001b[34mTypeError: not all arguments converted during string formatting\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"trial14xray.py\", line 388, in <module>\n",
      "    train(inceptionv3, args)\n",
      "  File \"trial14xray.py\", line 185, in train\n",
      "    train_loader, val_loader, test_loader = get_data_loader(args.data_dir, args.batch_size)\n",
      "  File \"trial14xray.py\", line 96, in get_data_loader\n",
      "    logger.info('Testing data:',len(test_data))\u001b[0m\n",
      "\u001b[34mMessage: 'Testing data:'\u001b[0m\n",
      "\u001b[34mArguments: (1024,)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 0: Train acc: 0.5593587521663779 | Validation acc: 0.4823529411764706\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 1: Train acc: 0.6637781629116117 | Validation acc: 0.5774509803921568\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 2: Train acc: 0.6817590987868284 | Validation acc: 0.6176470588235294\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 3: Train acc: 0.7110051993067591 | Validation acc: 0.6215686274509804\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 4: Train acc: 0.7205372616984402 | Validation acc: 0.6166666666666667\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 5: Train acc: 0.7346187175043327 | Validation acc: 0.6549019607843137\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 6: Train acc: 0.7419844020797227 | Validation acc: 0.638235294117647\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 7: Train acc: 0.7402512998266898 | Validation acc: 0.6411764705882353\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 8: Train acc: 0.7478336221837089 | Validation acc: 0.6441176470588236\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 9: Train acc: 0.7545493934142115 | Validation acc: 0.6607843137254902\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 10: Train acc: 0.7521663778162911 | Validation acc: 0.6803921568627451\u001b[0m\n",
      "\u001b[34mINFO:__main__:Epoch 11: Train acc: 0.7675476603119584 | Validation acc: 0.6774509803921569\u001b[0m\n",
      "\u001b[34mINFO:__main__:Training Finished! Plotting Graphs...\u001b[0m\n",
      "\u001b[34mINFO:__main__:Total time elapsed: 47259.44 seconds\u001b[0m\n",
      "\u001b[34mINFO:__main__:Final Training Accuracy: 0.8299393414211439\u001b[0m\n",
      "\u001b[34mINFO:__main__:Final Validation Accuracy: 0.711764705882353\u001b[0m\n",
      "\u001b[34mINFO:__main__:Graphs plotted...train() exited...\n",
      "\u001b[0m\n",
      "\n",
      "2021-04-04 08:59:43 Uploading - Uploading generated training model\n",
      "2021-04-04 09:02:23 Completed - Training job completed\n",
      "ProfilerReport-1617479176: IssuesFound\n",
      "Training seconds: 47621\n",
      "Billable seconds: 47621\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': dataset_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-biodiversity",
   "metadata": {
    "id": "violent-founder"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-activation",
   "metadata": {
    "id": "practical-substance"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "trial_6_xrays.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
