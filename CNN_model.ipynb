{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "bda6d754138e49b2ebf8b651a77a14698e425fe7435331076ed05b1488b86230"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-MnjtoY_Xsc"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FemEIn0OHRCv",
        "outputId": "0e5baa0f-4dd7-4078-c68b-09aa798bafe2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        " #Convolutional Neural Network Architecture for classifying chest xray images\n",
        "class Xray_Classifier(nn.Module):\n",
        "      def __init__(self):\n",
        "          self.name = \"Xray_Classifier\"\n",
        "          super(Xray_Classifier, self).__init__()\n",
        "          self.conv1 = nn.Conv2d(3, 5, 5) #in_channel=3, out_channel=5, kernel_size=5\n",
        "          self.pool = nn.MaxPool2d(2, 2) #kernel_size=2, stride=2 \n",
        "          self.conv2 = nn.Conv2d(5, 10, 5) #in_channel=5, out_channel=10, kernel_size=5\n",
        "          self.fc1 = nn.Linear(10*53*53, 30) #in_features=10*53*53, out_features=30\n",
        "          self.fc2 = nn.Linear(30, 4) #in_features=30, out_features=4\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = self.pool(F.relu(self.conv1(x))) #apply pooling to 1st convolution layer\n",
        "          x = self.pool(F.relu(self.conv2(x))) #apply pooling to 2nd convolution layer\n",
        "          x = x.view(-1, 10*53*53)\n",
        "          x = F.relu(self.fc1(x))\n",
        "          x = self.fc2(x)\n",
        "          return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "         \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "        \n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, batch_size=64, learning_rate=0.001, num_epochs=20):\n",
        "    torch.manual_seed(1000)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "          \n",
        "          \n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              #print(\"GPU is Available\")\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            #############################################\n",
        "            \n",
        "              \n",
        "            out = model(imgs)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy \n",
        "            val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy\n",
        "            n += 1\n",
        "\n",
        "        # Print the accuracies of validation and training for each epoch to observe how it changes over time \n",
        "        print(\"epoch number: \", epoch+1, \"Training accuracy: \",train_acc[epoch], \"Validation accuracy: \", val_acc[epoch])\n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), model_path)      \n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}